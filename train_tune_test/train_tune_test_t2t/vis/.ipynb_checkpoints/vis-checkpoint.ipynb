{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensor2tensor.utils import trainer_utils as utils\n",
    "from tensor2tensor.visualization import attention\n",
    "from tensor2tensor.utils import decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
       "  }\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "s=som\n",
    "t=eng\n",
    "source ../../../config.sh $s $t\n",
    "echo \"exp_dir: $exp_dir\" > config_local.yml\n",
    "echo \"s: $s\" >> config_local.yml\n",
    "echo \"t: $t\" >> config_local.yml\n",
    "echo \"trans_dir: $trans_dir\" >> config_local.yml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config_local.yml\") as f:\n",
    "    config = yaml.load(f)\n",
    "exp_dir = config[\"exp_dir\"]\n",
    "s = config[\"s\"]\n",
    "t = config[\"t\"]\n",
    "trans_dir = config[\"trans_dir\"]\n",
    "\n",
    "use_lex = \"\"\n",
    "emb_untrainable = \"\"\n",
    "emb_random = \"\"\n",
    "lex_cluster = \"\"\n",
    "# previos version: \n",
    "# before1d, after1d, before2d, after2d, beforesimple, aftersimple, beforesimpletanh, aftersimpletanh\n",
    "# current version: \n",
    "# beforeaggregate, afteraggregate, before1daggregate, after1daggregate, before2daggregate, after2daggregate, all1daggregate, al2daggregate\n",
    "attn = \"before1daggregate\"\n",
    "merge_ops = \"inf\" # 8000-8000, 8000, inf\n",
    "dim = 300 # 512, 300\n",
    "lr = 0.2\n",
    "dropout = 0.1\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "\n",
    "PROBLEM = \"translate_srctgt_lrlp\"\n",
    "#MODEL = \"transformer\" if attn == \"\" else \"transformer_lex\"+attn\n",
    "MODEL = \"transformer\" if attn == \"\" else \"transformer_lex\"\n",
    "HPARAMS = 'transformer_all'\n",
    "\n",
    "DATA_DIR = os.path.join(trans_dir, \"t2t_\"+merge_ops+use_lex)\n",
    "TRAIN_DIR= os.path.join(exp_dir, \"_\".join([\n",
    "    \"t2t\"+attn, \n",
    "    \"dim\"+str(dim), \n",
    "    \"layer\"+str(layer), \n",
    "    \"lr\"+str(lr), \n",
    "    \"dropout\"+str(dropout), \n",
    "    \"bpe\"+merge_ops\n",
    "    +use_lex\n",
    "    +emb_untrainable\n",
    "    +emb_random\n",
    "    +lex_cluster]))\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS.problems = PROBLEM\n",
    "FLAGS.hparams_set = HPARAMS\n",
    "FLAGS.data_dir = DATA_DIR\n",
    "FLAGS.model = MODEL\n",
    "\n",
    "FLAGS.schedule = \"train_and_evaluate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:batching_scheme = {'boundaries': [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 28, 30, 33, 36, 39, 42, 46, 50, 55, 60, 66, 72, 79, 86, 94, 103, 113, 124, 136, 149, 163, 179, 196, 215, 236], 'batch_sizes': [240, 180, 180, 180, 144, 144, 144, 120, 120, 120, 90, 90, 90, 90, 80, 72, 72, 60, 60, 48, 48, 48, 40, 40, 36, 30, 30, 24, 24, 20, 20, 18, 18, 16, 15, 12, 12, 10, 10, 9, 8, 8], 'min_length': 0, 'max_length': 1000000000, 'shuffle_queue_size': 270, 'window_size': 720}\n",
      "INFO:tensorflow:Updated batching_scheme = {'boundaries': [], 'batch_sizes': [1], 'min_length': 0, 'max_length': 1000000000, 'shuffle_queue_size': 270, 'window_size': 720}\n",
      "INFO:tensorflow:Reading data files from /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/translate_srctgt_lrlp-dev*\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(TRAIN_DIR)\n",
    "from reg_config.reg_hparams import *\n",
    "from reg_config.reg_problems import *\n",
    "from reg_config.reg_modalities import *\n",
    "from reg_config.reg_models import *\n",
    "\n",
    "hparams = utils.create_hparams(FLAGS.hparams_set, FLAGS.data_dir)\n",
    "\n",
    "# SET EXTRA HYPER PARAMS HERE!\n",
    "#hparams.null_slot = True\n",
    "\n",
    "utils.add_problem_hparams(hparams, PROBLEM)\n",
    "\n",
    "num_datashards = utils.devices.data_parallelism().n\n",
    "\n",
    "mode = tf.estimator.ModeKeys.EVAL\n",
    "\n",
    "input_fn = utils.input_fn_builder.build_input_fn(\n",
    "    mode=mode,\n",
    "    hparams=hparams,\n",
    "    data_dir=DATA_DIR,\n",
    "    num_datashards=num_datashards,\n",
    "    worker_replicas=FLAGS.worker_replicas,\n",
    "    worker_id=FLAGS.worker_id,\n",
    "    batch_size=1)\n",
    "\n",
    "inputs, target = input_fn()\n",
    "features = inputs\n",
    "features['targets'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {'inputs': ('symbol', 8003)}), ('input_space_id', 37), ('loss_multiplier', 1.0), ('max_expected_batch_size_per_shard', 64), ('target_modality', ('symbol', 8003)), ('target_space_id', 4), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7faa1e305e80>, 'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7faa1e282e48>}), ('was_copy', False), ('was_reversed', False)]\n"
     ]
    }
   ],
   "source": [
    "print(hparams.problems[0])\n",
    "\n",
    "# vocab_id: inputs, or targets\n",
    "def encode(string, vocab_id):\n",
    "    return [hparams.problems[0].vocabulary[vocab_id].encode(string) + [1] + [0]]\n",
    "\n",
    "def decode(ids, vocab_id):\n",
    "    return hparams.problems[0].vocabulary[vocab_id].decode(np.squeeze(ids))\n",
    "\n",
    "def to_tokens(ids, vocab_id):\n",
    "    ids = np.squeeze(ids)\n",
    "    tokenizer = hparams.problems[0].vocabulary[vocab_id]\n",
    "    tokens = []\n",
    "    for _id in ids:\n",
    "        if _id == 0:\n",
    "            tokens.append('<PAD>')\n",
    "        elif _id == 1:\n",
    "            tokens.append('<EOS>')\n",
    "        else:\n",
    "            if merge_ops != \"inf\":\n",
    "                tokens.append(tokenizer._subtoken_id_to_subtoken_string(_id))\n",
    "            else:\n",
    "                tokens.append(tokenizer._safe_id_to_token(_id))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "reading source vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.som\n",
      "source_vocab_size: 8003\n",
      "reading target vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.eng\n",
      "target_vocab_size: 8003\n",
      "reading source vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.som\n",
      "source_vocab_size: 8003\n",
      "reading target vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.eng\n",
      "target_vocab_size: 8003\n",
      "INFO:tensorflow:Doing model_fn_body took 1.635 sec.\n",
      "INFO:tensorflow:This model_fn took 1.880 sec.\n"
     ]
    }
   ],
   "source": [
    "model_fn = utils.model_builder.build_model_fn(\n",
    "    MODEL,\n",
    "    problem_names=[PROBLEM],\n",
    "    train_steps=FLAGS.train_steps,\n",
    "    worker_id=FLAGS.worker_id,\n",
    "    worker_replicas=FLAGS.worker_replicas,\n",
    "    eval_run_autoregressive=FLAGS.eval_run_autoregressive,\n",
    "    decode_hparams=decoding.decode_hparams(FLAGS.decode_hparams))\n",
    "est_spec = model_fn(features, target, mode, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "reading source vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.som\n",
      "source_vocab_size: 8003\n",
      "reading target vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.eng\n",
      "target_vocab_size: 8003\n",
      "reading source vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.som\n",
      "source_vocab_size: 8003\n",
      "reading target vocab from: /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/translation/t2t_inf/vocab.someng.8000.eng\n",
      "target_vocab_size: 8003\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n",
      "INFO:tensorflow:Doing model_fn_body took 1.240 sec.\n",
      "INFO:tensorflow:This model_fn took 1.411 sec.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "    beam_out = model_fn(features, target, tf.contrib.learn.ModeKeys.INFER, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/t2tbefore1daggregate_dim300_layer2_lr0.2_dropout0.1_bpeinf/model.ckpt-152841\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path /home/ec2-user/kklab/Projects/lrlp/experiment_2017.08.04.som-eng.y2r1.v1/t2tbefore1daggregate_dim300_layer2_lr0.2_dropout0.1_bpeinf/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 152841.\n"
     ]
    }
   ],
   "source": [
    "sv = tf.train.Supervisor(\n",
    "    logdir=TRAIN_DIR,\n",
    "    global_step=tf.Variable(0, dtype=tf.int64, trainable=False, name='global_step'))\n",
    "sess = sv.PrepareSession(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sv.StartQueueRunners(\n",
    "    sess,\n",
    "    tf.get_default_graph().get_collection(tf.GraphKeys.QUEUE_RUNNERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 152841.\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the attention tensors from the graph.\n",
    "# This need to be done using the training graph since the inference uses a tf.while_loop\n",
    "# and you cant fetch tensors from inside a while_loop.\n",
    "\n",
    "enc_atts = []\n",
    "dec_atts = []\n",
    "encdec_atts = []\n",
    "\n",
    "attn_1d = tf.get_default_graph().get_operation_by_name(\n",
    "    \"body/model/parallel_0/body/encoder/self_attention/multihead_attention/dot_product_attention/attention_weights\").values()[0]\n",
    "\n",
    "for i in range(hparams.num_hidden_layers):\n",
    "    enc_att = tf.get_default_graph().get_operation_by_name(\n",
    "        \"body/model/parallel_0/body/encoder/layer_%i/self_attention/multihead_attention/dot_product_attention/attention_weights\" % i).values()[0]\n",
    "    dec_att = tf.get_default_graph().get_operation_by_name(\n",
    "        \"body/model/parallel_0/body/decoder/layer_%i/self_attention/multihead_attention/dot_product_attention/attention_weights\" % i).values()[0]\n",
    "    encdec_att = tf.get_default_graph().get_operation_by_name(\n",
    "        \"body/model/parallel_0/body/decoder/layer_%i/encdec_attention/multihead_attention/dot_product_attention/attention_weights\" % i).values()[0]\n",
    "\n",
    "    enc_atts.append(enc_att)\n",
    "    dec_atts.append(dec_att)\n",
    "    encdec_atts.append(encdec_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:     wuxuu intaasi ku daray in UNK UNK ay ku dileen UNK ay diyaaradaha dagaalka Kenya ka fuliyeen meel aan wax badan ka fogeyn Ceel-cadde oo ah meesha lagu laayey ciidamada Kenya . <EOS>\n",
      "Gold:      he further stated that he was killed through an airstrike in a place not far from UNK where the attack took place . <EOS>\n",
      "Gold out:  he added added that the killed killed by his air carried the place not far from the El the Kenyan killed place of <EOS>\n"
     ]
    }
   ],
   "source": [
    "inp, out, logits = sess.run([inputs['inputs'], target, est_spec.predictions['predictions']])\n",
    "\n",
    "print(\"Input:    \", decode(inp[0], \"inputs\"))\n",
    "print(\"Gold:     \", decode(out[0], \"targets\"))\n",
    "logits = np.squeeze(logits[0])\n",
    "tokens = np.argmax(logits, axis=1)\n",
    "print(\"Gold out: \", decode(tokens, \"targets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_sent = \"dagaalka ayaa ka dhacay degmada Bayla ee gobolka Bari\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clashes occurred in the UNK district in the eastern region <EOS> <pad> <pad>\n",
      "INFO:tensorflow:Recording summary at step 152841.\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    }
   ],
   "source": [
    "inp_ids = encode(src_sent, \"inputs\")\n",
    "beam_decode = sess.run(\n",
    "    beam_out.predictions['outputs'], \n",
    "    {inputs['inputs']: np.expand_dims(np.expand_dims(inp_ids, axis=2), axis=3),}\n",
    ")\n",
    "trans = decode(beam_decode[0], \"targets\")\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_ids = beam_decode\n",
    "\n",
    "# Get attentions\n",
    "np_attn_1d, np_enc_atts, np_dec_atts, np_encdec_atts = sess.run(\n",
    "    [attn_1d, enc_atts, dec_atts, encdec_atts], \n",
    "    {\n",
    "        inputs['inputs']: np.expand_dims(np.expand_dims(inp_ids, axis=2), axis=3),\n",
    "        target: np.expand_dims(np.expand_dims(output_ids, axis=2), axis=3),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 4, 11, 11)\n",
      "(1, 4, 44, 44)\n",
      "INFO:tensorflow:Recording summary at step 152841.\n"
     ]
    }
   ],
   "source": [
    "inp_text = to_tokens(inp_ids, \"inputs\")\n",
    "out_text = to_tokens(output_ids, \"targets\")\n",
    "\n",
    "# [num_layers, batch_size, num_heads, enc/dec_length, enc/dec_length]\n",
    "print(np.array(np_enc_atts).shape)\n",
    "print(np.array(np_attn_1d).shape)\n",
    "\n",
    "# number of layers is set in attention.js (line 345)\n",
    "#attention.show(inp_text, out_text, np_enc_atts, np_dec_atts, np_encdec_atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os.path\n",
    "import heapq\n",
    "import random\n",
    "import math\n",
    "import theanolm\n",
    "\n",
    "sys.path.insert(0, '/home/ec2-user/kklab/Projects/lrlp/scripts/oov_translate')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### language model directory\n",
    "tmp_dir = exp_dir+\"oov_trans_wordlevel/\"\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lm(lm_model, \\\n",
    "             train_data, \\\n",
    "             dev_data, \\\n",
    "             vocab, \\\n",
    "             vocab_format, \\\n",
    "             arch, \\\n",
    "             learning_rate, \\\n",
    "             optimization_method, \\\n",
    "             stopping_condition, \\\n",
    "             validation_frequency, \\\n",
    "             patience):\n",
    "    '''\n",
    "    param:\n",
    "        lm_model: path to lm file\n",
    "        train_data: path to training data\n",
    "    '''\n",
    "    sh_realtime(\"theanolm train \"+\\\n",
    "               lm_model+\\\n",
    "               \" --training-set \"+train_data+\\\n",
    "               \" --validation-file \"+dev_data+\\\n",
    "               \" --vocabulary \"+vocab+\\\n",
    "               \" --vocabulary-format \"+vocab_format+\\\n",
    "               \" --architecture \"+arch+\\\n",
    "               \" --learning-rate \"+learning_rate+\\\n",
    "               \" --optimization-method \"+\\\n",
    "               \" --stopping-condition \"+stopping_condition+\\\n",
    "               \" --validation-frequency \"+validation_frequency+\\\n",
    "               \" --patience \"+patience)\n",
    "\n",
    "def find_prob(res_list):\n",
    "    ptr = -2\n",
    "    while 'log(p(</s> |' not in res_list[ptr]:\n",
    "        ptr -= 1\n",
    "    res = res_list[ptr]\n",
    "    return float(res.split(' = ')[-1])\n",
    "\n",
    "def score_sent(lm_model, all_sent):\n",
    "    '''\n",
    "    param:\n",
    "        lm_model: path to lm file\n",
    "        all_sent: path to file of all sentences to be scored\n",
    "    return:\n",
    "        scores: list of scores for sentences\n",
    "    '''\n",
    "    stdout, stderr = sh(\"theanolm score \"+lm_model+\" \"+all_sent+\" --output word-scores --log-base 10\")\n",
    "    stdout = stdout.split(\"\\n\\n\")\n",
    "    stdout = stdout[0:-1]\n",
    "    scores = [find_prob(item.split('\\n')) for item in stdout]\n",
    "    return scores\n",
    "\n",
    "def get_best_hyp_bynlm(lm_model, all_sentences):\n",
    "    '''\n",
    "    param:\n",
    "        lm_model: path to lm file\n",
    "        all_sent: list of sentences\n",
    "    return:\n",
    "        best_sent: a sentence from all_sent that has the highest score by lm\n",
    "    '''\n",
    "    with open(\"sent.tmp\", \"w\") as fw:\n",
    "        for sent in all_sentences:\n",
    "            fw.write(sent)\n",
    "            fw.write('\\n')\n",
    "    scores = score_sent(lm_model, \"sent.tmp\")\n",
    "    best_index = scores.index(max(scores))\n",
    "    return all_sentences[best_index], best_index\n",
    "\n",
    "def get_best_long_trans_bynlm(lm_model, tra_tok, oov_candidates):\n",
    "    '''\n",
    "    for sentences with lots of oovs, we translate oovs one by one,\n",
    "    for ug_dict\n",
    "    param:\n",
    "        lm_model: path to lm file\n",
    "        tra_tok: list of tokens\n",
    "        oov_candidates: {oov:{candidate:score}}\n",
    "    return:\n",
    "        best translation in string format\n",
    "    '''\n",
    "    tra_tok_new = list(tra_tok)\n",
    "    for i in range(len(tra_tok)):\n",
    "        if tra_tok[i] in oov_candidates and tra_tok[i] not in oov_candidates[tra_tok[i]]:\n",
    "            candidates = list(oov_candidates[tra_tok[i]].keys())\n",
    "            \n",
    "            all_hyp = []\n",
    "            for candidate in candidates:\n",
    "                sent = list(tra_tok_new)\n",
    "                sent[i] = candidate\n",
    "                all_hyp.append(' '.join(sent))\n",
    "            \n",
    "            _, best_index = get_best_hyp_bynlm(lm_model, all_hyp)\n",
    "            tra_tok_new[i] = candidates[best_index]\n",
    "    \n",
    "    return ' '.join(tra_tok_new)\n",
    "\n",
    "def get_best_long_trans_bynlm_eng_vocab(lm_model, tra_tok, oov_words_set, oov_candidates):\n",
    "    '''\n",
    "    for sentences with lots of oovs, we translate oovs one by one,\n",
    "    for eng_vocab\n",
    "    param:\n",
    "        lm_model: path to lm file\n",
    "        tra_tok: list of tokens\n",
    "        oov_words_set: set of oov words\n",
    "        oov_caniddates: {candidate:score}\n",
    "    return:\n",
    "        best translation in string format \n",
    "    '''\n",
    "    tra_tok_new = list(tra_tok)\n",
    "    for i in range(len(tra_tok)):\n",
    "        if tra_tok[i] in oov_words_set:\n",
    "            ### candidate translation, excluding candidates that appear in context\n",
    "            candidates = [candidate for candidate in oov_candidates if candidate not in tra_tok]\n",
    "            \n",
    "            all_hyp = []\n",
    "            for candidate in candidates:\n",
    "                sent = list(tra_tok_new)\n",
    "                sent[i] = candidate\n",
    "                all_hyp.append(' '.join(sent))\n",
    "            \n",
    "            _, best_index = get_best_hyp_bynlm(lm_model, all_hyp)\n",
    "            best_candidate = candidates[best_index]\n",
    "            tra_tok_new[i] = best_candidate\n",
    "    \n",
    "    return ' '.join(tra_tok_new)\n",
    "\n",
    "def oov_trans_wordlevel(candidate_source, add_aligned_oov, res_file):\n",
    "    lm_final_path = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/scripts/oov_translate/lm_neural/modelfun.h5\"\n",
    "\n",
    "    if candidate_source == \"ug_dict\":\n",
    "        ug_dict = get_ug_dict(oov_candidates_file, 0)\n",
    "    elif candidate_source == \"eng_vocab\":\n",
    "        eng_vocab = get_eng_vocab(eng_vocab_file)\n",
    "    multithread_routine([candidate_source, add_aligned_oov], \\\n",
    "                        res_file, \\\n",
    "                        [eng_vocab, ug_dict, lm_final_path], \\\n",
    "                        tmp_dir, \\\n",
    "                        wordlevel)\n",
    "\n",
    "\n",
    "class wordlevel (threading.Thread):\n",
    "    def __init__ (self, \\\n",
    "                  candidate_source, \\\n",
    "                  add_aligned_oov, \\\n",
    "                  res_file, \\\n",
    "                  ctr_lo, \\\n",
    "                  ctr_up, \\\n",
    "                  eng_vocab, \\\n",
    "                  ug_dict, \\\n",
    "                  lm_final_path):\n",
    "        threading.Thread.__init__(self)\n",
    "        \n",
    "        ### method params\n",
    "        self.candidate_source = candidate_source\n",
    "        self.add_aligned_oov = add_aligned_oov\n",
    "\n",
    "        ### one thread writes to one temporary file, later to be merged\n",
    "        self.res_file = res_file \n",
    "        \n",
    "        ### lower and upper bounds of instance indices\n",
    "        self.ctr_lo = ctr_lo\n",
    "        self.ctr_up = ctr_up\n",
    "        \n",
    "        ### established, cached resources, passed as arguments from outside\n",
    "        self.eng_vocab = eng_vocab\n",
    "        self.ug_dict = ug_dict\n",
    "        self.lm_final_path = lm_final_path\n",
    "    \n",
    "    def run(self):   \n",
    "        ctr = 0\n",
    "        with open(tra_file) as ft, \\\n",
    "        open(oov_file) as fo, \\\n",
    "        open(self.res_file, 'w') as fres:\n",
    "            for l_tra in ft:\n",
    "                l_oov = fo.readline()\n",
    "\n",
    "                if ctr >= self.ctr_lo and ctr <= self.ctr_up:\n",
    "                    \n",
    "                    ###\n",
    "                    # tra_tok: tokenized translation with oov, with html unescaped\n",
    "                    # oov_pos: oov word posistions\n",
    "                    # context: context word positions\n",
    "                    ###\n",
    "                    tra_tok, oov_pos, context = get_context_oov_pos(l_tra, l_oov)\n",
    "                    oov_words_set = set([tra_tok[i] for i in oov_pos])\n",
    "                    context_words_set = set([tra_tok[i] for i in context])\n",
    "\n",
    "                    ### get oov candidates\n",
    "                    oov_candidates = get_oov_candidates_all(self.candidate_source, \\\n",
    "                                                            self.add_aligned_oov, \\\n",
    "                                                            self.ug_dict, \\\n",
    "                                                            self.eng_vocab, \\\n",
    "                                                            oov_words_set, \\\n",
    "                                                            context_words_set)\n",
    "\n",
    "                    ### translate\n",
    "                    if candidate_source == \"ug_dict\":\n",
    "                        ### for test set: sentence 316 is super long\n",
    "                        ### for dev set: sentence 305, 452 is super long\n",
    "                        if dataset == \"dev\":\n",
    "                            s = [305, 452]\n",
    "                        elif dataset == \"test\":\n",
    "                            s = [316]\n",
    "\n",
    "                        if ctr not in s:\n",
    "                            all_sentences = get_all_sentences(tra_tok, oov_candidates)\n",
    "                            best_trans, _ = get_best_hyp_bynlm(self.lm_final_path, all_sentences)\n",
    "                        else:\n",
    "                            best_trans = get_best_long_trans_bynlm(self.lm_final_path, tra_tok, oov_candidates)\n",
    "                    elif candidate_source == \"eng_vocab\":\n",
    "                        best_trans = get_best_long_trans_bynlm_eng_vocab(self.lm_final_path, tra_tok, oov_words_set, oov_candidates)\n",
    "\n",
    "                    print(ctr)\n",
    "                    print(best_trans)\n",
    "                    fres.write(best_trans+'\\n')\n",
    "\n",
    "                ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "يورۇتۇلما colour ,\n",
      "1\n",
      "plan\n",
      "2\n",
      "Interactive Console for manipulating currently selected accessible\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63fadc4467b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mctr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mall_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtra_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mbest_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_hyp_bynlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_final_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0mbest_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_long_trans_bynlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_final_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtra_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-90360fba0bbf>\u001b[0m in \u001b[0;36mget_best_hyp_bynlm\u001b[0;34m(lm_model, all_sentences)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sent.tmp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mbest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-90360fba0bbf>\u001b[0m in \u001b[0;36mscore_sent\u001b[0;34m(lm_model, all_sent)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     '''\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theanolm score \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlm_model\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_sent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" --output word-scores --log-base 10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/kklab/Projects/lrlp/scripts/oov_translate/utils.py\u001b[0m in \u001b[0;36msh\u001b[0;34m(script, stdin)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         stdin=subprocess.PIPE)\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mScriptException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/kklab/src/anaconda3/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/kklab/src/anaconda3/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/kklab/src/anaconda3/lib/python3.5/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### ug_dict or eng_vocab\n",
    "for candidate_source in [\"ug_dict\", \"eng_vocab\"]:\n",
    "    if candidate_source == \"ug_dict\":\n",
    "        ### True or False, only meaningful when using ug_dict\n",
    "        for add_aligned_oov in [False, True]:\n",
    "            ### 4gram or wordlevel or charlevel\n",
    "            language_model = \"wordlevel\"\n",
    "\n",
    "            # -------- write --------\n",
    "            res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "            +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.eng_vocab.lm\"\n",
    "            if candidate_source == \"ug_dict\":\n",
    "                res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "                +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.ug_dict_withoutAlignedOov.lm\"\n",
    "                if add_aligned_oov:\n",
    "                    res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "                +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.ug_dict_withAlignedOov.lm\"\n",
    "            res_file += \"_\"+language_model\n",
    "\n",
    "            # -------- translate --------\n",
    "            oov_trans_wordlevel(candidate_source, add_aligned_oov, resfile)\n",
    "    else:\n",
    "        add_aligned_oov = False\n",
    "        ### 4gram or wordlevel or charlevel\n",
    "        language_model = \"wordlevel\"\n",
    "\n",
    "        # -------- write --------\n",
    "        res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "        +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.eng_vocab.lm\"\n",
    "        if candidate_source == \"ug_dict\":\n",
    "            res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "            +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.ug_dict_withoutAlignedOov.lm\"\n",
    "            if add_aligned_oov:\n",
    "                res_file = \"/home/ec2-user/kklab/Projects/lrlp/experiment_elisa.il3-eng.y1r1.v2/translation/\"\\\n",
    "            +dataset+\"/elisa.il3-eng.test.y1r1.v2.translated.eng.oovtranslated.ug_dict_withAlignedOov.lm\"\n",
    "        res_file += \"_\"+language_model\n",
    "\n",
    "        # -------- translate --------\n",
    "        oov_trans_wordlevel(candidate_source, add_aligned_oov, resfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
